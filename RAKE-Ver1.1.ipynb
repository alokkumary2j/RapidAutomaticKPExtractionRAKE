{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import operator\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isPunct(word):\n",
    "    return len(word) == 1 and word in string.punctuation\n",
    "\n",
    "def isNumeric(word):\n",
    "    try:\n",
    "        float(word) if '.' in word else int(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RakeKeywordExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words())\n",
    "        self.top_fraction = 1 # consider top third candidate keywords by score\n",
    "\n",
    "    def _generate_candidate_keywords(self, sentences):\n",
    "        phrase_list = []\n",
    "        for sentence in sentences:\n",
    "            words = map(lambda x: \"|\" if x in self.stopwords else x,nltk.word_tokenize(sentence.lower()))\n",
    "            ##words => NONSTOPWORD | NONSTOPWORD NONSTOPWORD NONSTOPWORD | | NONSTOPWORD | NONSTOPWORD NONSTOPWORD |\n",
    "            phrase = []\n",
    "            for word in words:\n",
    "                if word == \"|\" or isPunct(word):\n",
    "                    if len(phrase) > 0:\n",
    "                        phrase_list.append(phrase)#Got At least 1 NonStopWord\n",
    "                    phrase = []#Prepare for Next Continous NonStopWords\n",
    "                else:\n",
    "                    phrase.append(word)#NonStopWord\n",
    "        return phrase_list\n",
    "\n",
    "    def _calculate_word_scores(self, phrase_list):\n",
    "        word_freq = nltk.FreqDist()\n",
    "        word_degree = nltk.FreqDist()\n",
    "        for phrase in phrase_list:\n",
    "            degree = len(list(filter(lambda x: not isNumeric(x), phrase))) #Number of Distinct Words in the Phrase\n",
    "            for word in phrase:\n",
    "                word_freq[word] += 1\n",
    "                word_degree[word]+=degree\n",
    "        # word score = deg(w) / freq(w)\n",
    "        word_scores = {}\n",
    "        for word in word_freq.keys():\n",
    "            word_scores[word] = word_degree[word] / word_freq[word]\n",
    "        return word_scores\n",
    "\n",
    "    def _calculate_phrase_scores(self, phrase_list, word_scores):\n",
    "        phrase_scores = {}\n",
    "        for phrase in phrase_list:\n",
    "            phrase_score = 0\n",
    "            for word in phrase:\n",
    "                phrase_score += word_scores[word]\n",
    "                phrase_scores[\" \".join(phrase)] = phrase_score\n",
    "        return phrase_scores\n",
    "    \n",
    "    def extract(self, text, incl_scores=False):\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        phrase_list = self._generate_candidate_keywords(sentences)\n",
    "        word_scores = self._calculate_word_scores(phrase_list)\n",
    "        phrase_scores = self._calculate_phrase_scores(phrase_list, word_scores)\n",
    "        sorted_phrase_scores = sorted(phrase_scores.items(),\n",
    "        key=operator.itemgetter(1), reverse=True)\n",
    "        n_phrases = len(sorted_phrase_scores)\n",
    "        if incl_scores:\n",
    "            return sorted_phrase_scores[0:int(n_phrases/self.top_fraction)]\n",
    "        else:\n",
    "            return map(lambda x: x[0],sorted_phrase_scores[0:int(n_phrases/self.top_fraction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('minimal generating sets', 8.666666666666666),\n",
       " ('linear diophantine equations', 8.5),\n",
       " ('minimal supporting set', 7.666666666666666),\n",
       " ('minimal set', 4.666666666666666),\n",
       " ('linear constraints', 4.5),\n",
       " ('strict inequations', 4.0),\n",
       " ('natural numbers', 4.0),\n",
       " ('upper bounds', 4.0),\n",
       " ('nonstrict inequations', 4.0),\n",
       " ('mixed types', 3.666666666666667),\n",
       " ('corresponding algorithms', 3.5),\n",
       " ('considered types', 3.166666666666667),\n",
       " ('set', 2.0),\n",
       " ('types', 1.6666666666666667),\n",
       " ('considered', 1.5),\n",
       " ('algorithms', 1.5),\n",
       " ('systems', 1.0),\n",
       " ('solutions', 1.0),\n",
       " ('solving', 1.0),\n",
       " ('system', 1.0),\n",
       " ('criteria', 1.0),\n",
       " ('construction', 1.0),\n",
       " ('given', 1.0),\n",
       " ('used', 1.0),\n",
       " ('constructing', 1.0),\n",
       " ('compatibility', 1.0),\n",
       " ('components', 1.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(feedback):\n",
    "    rake = RakeKeywordExtractor()\n",
    "    keywords = rake.extract(feedback, incl_scores=True)\n",
    "    return keywords\n",
    "f1=\"\"\"\n",
    "    Compatibility of systems of linear constraints over the set of natural \n",
    "    numbers. Criteria of compatibility of a system of linear Diophantine \n",
    "    equations, strict inequations, and nonstrict inequations are considered. \n",
    "    Upper bounds for components of a minimal set of solutions and algorithms \n",
    "    of construction of minimal generating sets of solutions for all types of \n",
    "    systems are given. These criteria and the corresponding algorithms for \n",
    "    constructing a minimal supporting set of solutions can be used in solving \n",
    "    all the considered types of systems and systems of mixed types.\n",
    "    \"\"\" \n",
    "test(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "def parse(filename):\n",
    "    with open(filename) as data_file:\n",
    "        data = json.load(data_file) \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsedData=parse(\"Musical_Instruments_5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commentText=[]\n",
    "rakeTags=[]\n",
    "amazonMusicReviewDF=pd.DataFrame(columns=[\"ReviewText\",\"RakePhrases\"])\n",
    "for i in np.arange(10):\n",
    "    amazonMusicReviewDF.loc[i]=[parsedData[i][\"reviewText\"],test(parsedData[i][\"reviewText\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck is only marginally able to hold the screen in position and requires careful positioning of the clamp to avoid sagging.',\n",
       " [('requires careful positioning', 9.0),\n",
       "  ('nice windscreen protects', 9.0),\n",
       "  ('avoid sagging', 4.0),\n",
       "  ('marginally able', 4.0),\n",
       "  ('mxl mic', 4.0),\n",
       "  ('prevents pops', 4.0),\n",
       "  ('thing', 1.0),\n",
       "  ('gooseneck', 1.0),\n",
       "  ('screen', 1.0),\n",
       "  ('position', 1.0),\n",
       "  ('clamp', 1.0),\n",
       "  ('hold', 1.0)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazonMusicReviewDF.loc[3].ReviewText,amazonMusicReviewDF.loc[3].RakePhrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"This pop filter is great. It looks and performs like a studio filter. If you're recording vocals this will eliminate the pops that gets recorded when you sing.\",\n",
       " [(\"'re recording vocals\", 9.0),\n",
       "  ('pop filter', 4.0),\n",
       "  ('studio filter', 4.0),\n",
       "  ('performs like', 4.0),\n",
       "  ('gets recorded', 4.0),\n",
       "  ('eliminate', 1.0),\n",
       "  ('sing', 1.0),\n",
       "  ('looks', 1.0),\n",
       "  ('pops', 1.0),\n",
       "  ('great', 1.0)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=4\n",
    "amazonMusicReviewDF.loc[i].ReviewText,amazonMusicReviewDF.loc[i].RakePhrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I now use this cable to run from the output of my pedal chain to the input of my Fender Amp. After I bought Monster Cable to hook up my pedal board I thought I would try another one and update my guitar. I had been using a high end Planet Waves cable that I bought in the 1980's... Once I found out the input jacks on the new Monster cable didn't fit into the Fender Strat jack I was a little disappointed... I didn't return it and as stated I use it for the output on the pedal board. Save your money... I went back to my Planet Waves Cable...I payed $30.00 back in the eighties for the Planet Waves which now comes in at around $50.00. What I'm getting at is you get what you pay for. I thought Waves was a lot of money back in the day...but I haven't bought a guitar cable since this one...20 plus years and still working...Planet Waves wins.\",\n",
       " [('still working ... planet waves wins', 28.75),\n",
       "  ('one ... 20 plus years', 19.6),\n",
       "  ('would try another one', 16.0),\n",
       "  ('planet waves cable ...', 13.583333333333334),\n",
       "  ('planet waves cable', 9.983333333333334),\n",
       "  ('new monster cable', 8.833333333333334),\n",
       "  ('fender strat jack', 8.5),\n",
       "  ('bought monster cable', 7.833333333333334),\n",
       "  ('guitar cable since', 7.833333333333334),\n",
       "  (\"1980 's ...\", 7.6),\n",
       "  ('planet waves', 7.15),\n",
       "  ('day ...', 5.6),\n",
       "  ('thought waves', 4.9),\n",
       "  ('fender amp', 4.5),\n",
       "  (\"n't bought\", 4.0),\n",
       "  (\"'m getting\", 4.0),\n",
       "  (\"n't return\", 4.0),\n",
       "  ('pedal chain', 4.0),\n",
       "  (\"n't fit\", 4.0),\n",
       "  ('pedal board', 4.0),\n",
       "  ('went back', 3.666666666666667),\n",
       "  ('money back', 3.666666666666667),\n",
       "  ('input jacks', 3.5),\n",
       "  ('cable', 2.8333333333333335),\n",
       "  ('30.00 back', 2.666666666666667),\n",
       "  ('bought', 2.0),\n",
       "  ('guitar', 2.0),\n",
       "  ('input', 1.5),\n",
       "  ('thought', 1.5),\n",
       "  ('payed', 1.0),\n",
       "  ('stated', 1.0),\n",
       "  ('output', 1.0),\n",
       "  ('save', 1.0),\n",
       "  ('pay', 1.0),\n",
       "  ('found', 1.0),\n",
       "  ('get', 1.0),\n",
       "  ('lot', 1.0),\n",
       "  ('around', 1.0),\n",
       "  ('update', 1.0),\n",
       "  ('comes', 1.0),\n",
       "  ('eighties', 1.0),\n",
       "  ('using', 1.0),\n",
       "  ('use', 1.0),\n",
       "  ('high', 1.0),\n",
       "  ('hook', 1.0),\n",
       "  ('run', 1.0),\n",
       "  ('50.00', 0.0)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=7\n",
    "amazonMusicReviewDF.loc[i].ReviewText,amazonMusicReviewDF.loc[i].RakePhrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RakeWithPMIKeywordExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words())\n",
    "        self.top_fraction = 1 # consider top third candidate keywords by score\n",
    "\n",
    "    def _generate_candidate_keywords(self, sentences):\n",
    "        phrase_list = []\n",
    "        for sentence in sentences:\n",
    "            words = map(lambda x: \"|\" if x in self.stopwords else x,nltk.word_tokenize(sentence.lower()))\n",
    "            ##words => NONSTOPWORD | NONSTOPWORD NONSTOPWORD NONSTOPWORD | | NONSTOPWORD | NONSTOPWORD NONSTOPWORD |\n",
    "            phrase = []\n",
    "            for word in words:\n",
    "                if word == \"|\" or isPunct(word):\n",
    "                    if len(phrase) > 0:\n",
    "                        phrase_list.append(phrase)#Got At least 1 NonStopWord\n",
    "                    phrase = []#Prepare for Next Continous NonStopWords\n",
    "                else:\n",
    "                    phrase.append(word)#NonStopWord\n",
    "        return phrase_list\n",
    "\n",
    "    def _chkAndAddDictEntry(self,dictObj,key,value=1):\n",
    "        if dictObj.get(key)==None:\n",
    "            dictObj[key]=value\n",
    "        else:\n",
    "            dictObj[key]+=value\n",
    "    def _chkAndInitiateDictEntry(self,dictOfDictObj,key,initialDict):\n",
    "        if dictOfDictObj.get(key)==None:\n",
    "            dictOfDictObj[key]=initialDict;\n",
    "        return dictOfDictObj[key]\n",
    "    #This implementation of PMI does ignore reapeating words in a KeyPhrase\n",
    "    def _preparePMIDPMatrix(self,all_phrase_lists):\n",
    "        corpusLevelDict={}#It is Symmetric corpusLevelDict[\"w1\"][\"w2\"]=corpusLevelDict[\"w2\"][\"w1\"]\n",
    "        wordLevelDict={}\n",
    "        for phrase_list_all in all_phrase_lists:\n",
    "            phrase_list=set(phrase_list_all)\n",
    "            for word in phrase_list:\n",
    "                wordLevelDict=self._chkAndInitiateDictEntry(corpusLevelDict,word,{})\n",
    "                for neighWord in phrase_list:\n",
    "                    if word==neighWord:\n",
    "                        continue\n",
    "                    self._chkAndAddDictEntry(wordLevelDict,neighWord)\n",
    "        corpusDictSz=len(corpusLevelDict.keys())         \n",
    "        print(\"Corpus Dictionary Size \",corpusDictSz)\n",
    "        print(\"Total KeyPhrases \",len(all_phrase_lists))\n",
    "        return corpusLevelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getListOfPharases(reviewDF,fieldName):\n",
    "    listOfPhrases=[]\n",
    "    rakePhrases=reviewDF[fieldName]\n",
    "    for i in np.arange(len(rakePhrases)):\n",
    "        rakePhrase=rakePhrases[i]\n",
    "        for j in np.arange(len(rakePhrase)):\n",
    "            listOfPhrases.append(rakePhrase[j][0].split(\" \"))\n",
    "    return listOfPhrases\n",
    "def testPMI():\n",
    "    listOfPhrases=getListOfPharases(amazonMusicReviewDF,\"RakePhrases\")\n",
    "    rake = RakeWithPMIKeywordExtractor()\n",
    "    return rake._preparePMIDPMatrix(listOfPhrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Dictionary Size  239\n",
      "Total KeyPhrases  187\n"
     ]
    }
   ],
   "source": [
    "topLevelDict=testPMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prices': 1, 'filters': 1, 'pop': 1}\n",
      "{'filters': 1, 'sounds': 1, 'prices': 1, 'filter': 3, 'lowest': 1, 'next': 1}\n",
      "{'prices': 1, 'lowest': 1, 'pop': 1}\n",
      "{'studio': 1, 'pop': 3, 'cloth': 1, 'double': 1, 'blocks': 1, 'next': 1}\n"
     ]
    }
   ],
   "source": [
    "print(topLevelDict[\"lowest\"])\n",
    "print(topLevelDict[\"pop\"])\n",
    "print(topLevelDict[\"filters\"])\n",
    "print(topLevelDict[\"filter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listOfPhrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpusLevelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w2', 'ab', 'w3'}\n",
      "{'w1', 'cd', 'w2'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "p1=[[\"ab\",\"w2\",\"w3\"],[\"cd\",\"w1\",\"w2\",\"cd\"],[]]\n",
    "for phrase_list_all in p1:\n",
    "    phrase_list=set(phrase_list_all)\n",
    "    print(phrase_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hj': 156, 'nota': {'notb': 45.1435}, 'pyth': {}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topLevelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topLevelDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazonMusicReviewDF.to_excel(\"AmazonMusicReview_RakeKeyPharses.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
